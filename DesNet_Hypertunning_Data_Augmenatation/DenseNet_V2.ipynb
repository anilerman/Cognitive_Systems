{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJDpPjYTqDOq",
        "outputId": "84d06954-3b75-4d6b-d1cb-53e24151b8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Grpt5-2qlrz",
        "outputId": "7da6d232-5c95-4d42-940b-2ddfcf3ad134",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch CUDA Version:\", torch.version.cuda)\n",
        "\n",
        "print(\"Current CUDA Device:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af6zI_8Mq7PA",
        "outputId": "8f1595f0-52e2-49bf-ca5a-b22ec8c9d56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch CUDA Version: 12.1\n",
            "Current CUDA Device: NVIDIA L4\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7CrqN-8ik4H",
        "outputId": "8b0e69fa-6c31-4ded-bc52-9e8c8fbc30b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "True\n",
            "NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/DeepLearningProject/chest_xray/chest_xray'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model_ft = models.densenet121(pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / dataset_sizes['test']\n",
        "    print('Test Acc: {:4f}'.format(test_acc))\n",
        "\n",
        "\n",
        "model_path = '/content/drive/MyDrive/DeepLearningProject/Saved_Models/Resnest_Model_Without_Augumentation.pth'\n",
        "torch.save(model_ft.state_dict(), model_path)\n",
        "print(f'Model saved to {model_path}')\n",
        "\n",
        "\n",
        "test_model(model_ft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwXKMElRizSB",
        "outputId": "8ab0a305-6fe3-4a00-efa1-2440a1ff82ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 162MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.2791 Acc: 0.8823\n",
            "val Loss: 0.4991 Acc: 0.7500\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.1738 Acc: 0.9321\n",
            "val Loss: 0.9890 Acc: 0.6875\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1592 Acc: 0.9399\n",
            "val Loss: 0.5618 Acc: 0.8125\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.1322 Acc: 0.9471\n",
            "val Loss: 0.8935 Acc: 0.6250\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.1370 Acc: 0.9466\n",
            "val Loss: 0.4494 Acc: 0.8125\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.1286 Acc: 0.9511\n",
            "val Loss: 0.2448 Acc: 0.9375\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.1188 Acc: 0.9541\n",
            "val Loss: 0.8215 Acc: 0.6250\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1054 Acc: 0.9606\n",
            "val Loss: 0.6339 Acc: 0.6875\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.1040 Acc: 0.9613\n",
            "val Loss: 0.4243 Acc: 0.7500\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0990 Acc: 0.9615\n",
            "val Loss: 0.5356 Acc: 0.6875\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0972 Acc: 0.9638\n",
            "val Loss: 0.5400 Acc: 0.6875\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1016 Acc: 0.9632\n",
            "val Loss: 0.5856 Acc: 0.7500\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0992 Acc: 0.9613\n",
            "val Loss: 0.4193 Acc: 0.8125\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0926 Acc: 0.9659\n",
            "val Loss: 0.7813 Acc: 0.6250\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0975 Acc: 0.9638\n",
            "val Loss: 0.5489 Acc: 0.7500\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0945 Acc: 0.9630\n",
            "val Loss: 0.5537 Acc: 0.7500\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0920 Acc: 0.9638\n",
            "val Loss: 0.5738 Acc: 0.7500\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0913 Acc: 0.9676\n",
            "val Loss: 0.6593 Acc: 0.6875\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0924 Acc: 0.9649\n",
            "val Loss: 0.5921 Acc: 0.6875\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0900 Acc: 0.9672\n",
            "val Loss: 0.4920 Acc: 0.7500\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0909 Acc: 0.9642\n",
            "val Loss: 0.4736 Acc: 0.7500\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0895 Acc: 0.9685\n",
            "val Loss: 0.4535 Acc: 0.7500\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0915 Acc: 0.9659\n",
            "val Loss: 0.4971 Acc: 0.7500\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0942 Acc: 0.9674\n",
            "val Loss: 0.4899 Acc: 0.7500\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0912 Acc: 0.9649\n",
            "val Loss: 0.6393 Acc: 0.6875\n",
            "\n",
            "Training complete in 42m 23s\n",
            "Best val Acc: 0.937500\n",
            "Model saved to /content/drive/MyDrive/DeepLearningProject/Saved_Models/Resnest_Model_Without_Augumentation.pth\n",
            "Test Acc: 0.947115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/DeepLearningProject/chest_xray/chest_xray'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model_ft = models.densenet121(pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, model_save_path='/path/to/save/model.pth'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f'Model saved to {model_save_path}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/DeepLearningProject/Saved_Models/Resnest_Model_With_Augumentation.pth'\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25, model_save_path=model_save_path)\n",
        "\n",
        "\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / dataset_sizes['test']\n",
        "    print('Test Acc: {:4f}'.format(test_acc))\n",
        "\n",
        "\n",
        "test_model(model_ft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScLe556yz_d7",
        "outputId": "56c625da-f60d-44bd-cc95-2d2478d52494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 186MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.3094 Acc: 0.8660\n",
            "val Loss: 0.3650 Acc: 0.8125\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.2159 Acc: 0.9117\n",
            "val Loss: 0.4156 Acc: 0.6875\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1895 Acc: 0.9238\n",
            "val Loss: 0.5785 Acc: 0.6875\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.1755 Acc: 0.9323\n",
            "val Loss: 0.3338 Acc: 0.8750\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.1635 Acc: 0.9344\n",
            "val Loss: 0.6992 Acc: 0.6875\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.1554 Acc: 0.9397\n",
            "val Loss: 0.3735 Acc: 0.8125\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.1573 Acc: 0.9378\n",
            "val Loss: 0.4385 Acc: 0.7500\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1390 Acc: 0.9460\n",
            "val Loss: 0.4821 Acc: 0.7500\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.1308 Acc: 0.9500\n",
            "val Loss: 0.3171 Acc: 0.8125\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.1388 Acc: 0.9492\n",
            "val Loss: 0.2858 Acc: 0.8750\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1272 Acc: 0.9545\n",
            "val Loss: 0.3744 Acc: 0.8125\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1330 Acc: 0.9502\n",
            "val Loss: 0.3774 Acc: 0.8125\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.1348 Acc: 0.9481\n",
            "val Loss: 0.3628 Acc: 0.8125\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.1411 Acc: 0.9426\n",
            "val Loss: 0.3172 Acc: 0.8125\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.1229 Acc: 0.9520\n",
            "val Loss: 0.3562 Acc: 0.8125\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1291 Acc: 0.9538\n",
            "val Loss: 0.3324 Acc: 0.8125\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1251 Acc: 0.9536\n",
            "val Loss: 0.2698 Acc: 0.8125\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.1246 Acc: 0.9543\n",
            "val Loss: 0.3050 Acc: 0.8125\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.1304 Acc: 0.9515\n",
            "val Loss: 0.3614 Acc: 0.8125\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1367 Acc: 0.9500\n",
            "val Loss: 0.3466 Acc: 0.8125\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.1252 Acc: 0.9553\n",
            "val Loss: 0.3113 Acc: 0.8125\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1288 Acc: 0.9519\n",
            "val Loss: 0.2639 Acc: 0.8125\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1210 Acc: 0.9553\n",
            "val Loss: 0.3452 Acc: 0.8125\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1234 Acc: 0.9528\n",
            "val Loss: 0.3109 Acc: 0.8125\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1248 Acc: 0.9515\n",
            "val Loss: 0.2715 Acc: 0.8125\n",
            "\n",
            "Training complete in 24m 18s\n",
            "Best val Acc: 0.875000\n",
            "Model saved to /content/drive/MyDrive/DeepLearningProject/Saved_Models/Resnest_Model_With_Augumentation.pth\n",
            "Test Acc: 0.924679\n"
          ]
        }
      ]
    }
  ]
}